{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/watermelonDrip/Collected-Mistakes/blob/main/ML_Exercise2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCoqe6lJt0s9"
      },
      "source": [
        "# 机器学习练习 2 - 逻辑回归"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-QGRXxdt0tB"
      },
      "source": [
        "这个笔记包含了以Python为编程语言的Coursera上机器学习的第二次编程练习。请参考 [作业文件](ex2.pdf) 详细描述和方程。\n",
        "在这一次练习中，我们将要实现逻辑回归并且应用到一个分类任务。我们还将通过将正则化加入训练算法，来提高算法的鲁棒性，并用更复杂的情形来测试它。\n",
        "\n",
        "代码修改并注释：黄海广，haiguang2000@qq.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd0hem5Mt0tC"
      },
      "source": [
        "## 逻辑回归"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfLMF5NKt0tC"
      },
      "source": [
        "在训练的初始阶段，我们将要构建一个逻辑回归模型来预测，某个学生是否被大学录取。设想你是大学相关部分的管理者，想通过申请学生两次测试的评分，来决定他们是否被录取。现在你拥有之前申请学生的可以用于训练逻辑回归的训练样本集。对于每一个训练样本，你有他们两次测试的评分和最后是被录取的结果。为了完成这个预测任务，我们准备构建一个可以基于两次测试评分来评估录取可能性的分类模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lsI9eNGt0tD"
      },
      "source": [
        "让我们从检查数据开始。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "collapsed": true,
        "id": "5s5Dhd0qt0tD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "wckrdmbWAg4F"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vgWIPspnt0tF",
        "outputId": "c9dc86dc-b91c-4f11-9c32-264387385b69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5c329b42-22e4-45fa-9589-16de5ba843e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Exam 1</th>\n",
              "      <th>Exam 2</th>\n",
              "      <th>Admitted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34.623660</td>\n",
              "      <td>78.024693</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30.286711</td>\n",
              "      <td>43.894998</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35.847409</td>\n",
              "      <td>72.902198</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60.182599</td>\n",
              "      <td>86.308552</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>79.032736</td>\n",
              "      <td>75.344376</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c329b42-22e4-45fa-9589-16de5ba843e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c329b42-22e4-45fa-9589-16de5ba843e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c329b42-22e4-45fa-9589-16de5ba843e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Exam 1     Exam 2  Admitted\n",
              "0  34.623660  78.024693         0\n",
              "1  30.286711  43.894998         0\n",
              "2  35.847409  72.902198         0\n",
              "3  60.182599  86.308552         1\n",
              "4  79.032736  75.344376         1"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "path = 'ex2data1.txt'\n",
        "data = pd.read_csv(path, header=None, names=['Exam 1', 'Exam 2', 'Admitted'])\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrcMlFoZt0tG"
      },
      "source": [
        "让我们创建两个分数的散点图，并使用颜色编码来可视化，如果样本是正的（被接纳）或负的（未被接纳）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "HxNPtGzit0tH",
        "outputId": "fc6f6235-6052-4313-bedc-acf70ee78724"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAHgCAYAAABn8uGvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdf3ScdZn//9cVqPxIRhFEPmywUmkUFgsFokekEBbULZXFNKumriLrdunu6lf6w8XW8/Ws7ud8dkHwfLJh110/bNFlz2KJYhpw7ceFL4hSdXFTtwJSNa0ULAVRAZ1EQCDX94/33M10MpNMJjNz3/fcz8c5PXfmPZPknTvTyXW/53pfl7m7AAAAAMxdW9wTAAAAANKKYBoAAACoEcE0AAAAUCOCaQAAAKBGBNMAAABAjQimAQAAgBodGvcE5uMVr3iFn3jiiXFPAwAAAC1ux44dv3D3Y0vHUx1Mn3jiiRodHY17GgAAAGhxZvZwuXHSPAAAAIAaEUwDAAAANSKYBgAAAGqU6pxpAACAtHr++ee1b98+Pfvss3FPBUUOP/xwnXDCCVqwYEFVjyeYBgAAiMG+ffuUy+V04oknyszing4kubt++ctfat++fVq0aFFVn0OaBwAAQAyeffZZHXPMMQTSCWJmOuaYY+b0bgHBNAAAQEwIpJNnrr+ThgXTZvY5M3vCzB4oGjvazO4ws7HC8eWFcTOz68xst5ndZ2ZnNmpeAAAAmDIyMiIz0w9/+MOy959//vlz6usxOjqqK664QpJ0991369vf/vZB3+vBBx+c8xw7Ojrm/DnN0siV6X+RtLxkbJOkO929S9KdhduSdJGkrsK/NZL+qYHzAgAASJ18Xtq8Wdq4MRzz+fp83S1btmjZsmXasmVLXb5ed3e3rrvuOkn1C6aTrGHBtLt/U9KTJcPvkHRj4eMbJfUWjf+rB/8p6SgzO75RcwMAAEiT7dulzk5p3TrpmmvCsbMzjM/H+Pi4tm/frhtuuEE333yzJOmZZ57RqlWrdMopp2jlypV65plnDjy+o6NDV155pU499VS95S1v0Xe/+12df/75es1rXqPbbrtNUgigL774Yu3du1ef/exnNTAwoKVLl+ob3/iGbrvtNl155ZVaunSp9uzZoz179mj58uU666yzdO655x5YHX/ooYd09tlna8mSJfr4xz8+vx+ywZpdzeM4d3+s8PHjko4rfNwp6adFj9tXGHtMAAAAGZbPSytWHLwSPTERjitWSPv3S7VmQdx6661avny5Xvva1+qYY47Rjh079I1vfENHHnmkdu3apfvuu09nnjmVfTsxMaELLrhA1157rVauXKmPf/zjuuOOO/Tggw/qsssu0yWXXHLgsSeeeKL+/M//XB0dHfrLv/xLSdIll1yiiy++WO985zslSRdeeKE++9nPqqurS/fee68++MEP6q677tLatWv1F3/xF3r/+9+vz3zmM7X9cE0SW2k8d3cz87l+npmtUUgF0cKFC+s+LwAAgCQZGpImJ8vfNzkZ7l+9uravvWXLFq1du1aStGrVKm3ZskW7d+8+kPN82mmn6bTTTjvw+Je85CVavjxk8S5ZskSHHXaYFixYoCVLlmjv3r1z+t7j4+P69re/rXe9610Hxp577jlJ0re+9S19+ctfliRdeuml2rhxY20/YBM0O5j+mZkd7+6PFdI4niiMPyrpVUWPO6EwNo27Xy/peknq7u6eczAOAACQJmNjUyvRpSYmpN27a/u6Tz75pO666y7df//9MjO9+OKLMjOdccYZFT9nwYIFB6pdtLW16bDDDjvw8QsvvDCn7z85OamjjjpKO3fuLHt/WiqdNLs03m2SLit8fJmkW4vG31+o6vEmSb8qSgcBAADIrK4uqb29/H3t7dLixbV93VtuuUWXXnqpHn74Ye3du1c//elPtWjRIp111ln6whe+IEl64IEHdN9999U4cymXyylflJ9SfPulL32pFi1apC996UuSQsOU73//+5Kkc84550AO90033VTz92+GRpbG2yLpO5JeZ2b7zGy1pKslvdXMxiS9pXBbkrZJ+omk3ZL+WdIHGzWvVHOXtm4Nx2rGAQBA6vX3S20VIra2tnB/LbZs2aKVK1ceNPaHf/iHeuihhzQ+Pq5TTjlFf/VXf6Wzzjqrtm8g6Q/+4A+0detWLV26VPfcc49WrVqla6+9VmeccYb27Nmjm266STfccINOP/10nXrqqbr11rDOOjg4qM985jNasmSJHn20bLJCYpinOADr7u72udQ9TL2tW6W+PmntWmlgQDILAfT69dLgoDQ8LJX8pwAAAMm0a9cunXLKKVU9dvv2sNlwcjKkdrS3h0B62zZp2bIGTzSDyv1uzGyHu3eXPja2DYioQW9vCKQHB8PtgYGpQHrt2nA/AABoOcuWhaodQ0MhR3rx4rAineBeJplBMJ0mZiGAlkIAHQXVxSvVAACgJXV01F61A43T7A2ImK/igDpCIA0AABALgum0iXKki61fz+ZDAACAGBBMp0nxZsO1a8MuhCiHmoAaQErl89LmzdLGjeFY3OUNAJKOnOk0GRmZCqSj1I7iHOqenpap5pHPh00WY2OhvmZ/v5TLxT0rAPVWrkLBhg1UKACQHqxMp0lvbyh/V5wjHQXUw8MtU81j+3aps1Nat0665ppw7OwM4wBaRz4fAul8fqq728TE1Pj4eLzzA7LAzPSRj3zkwO1Pf/rT+uQnPznj54yMjOjBBx+c8TFLly7VqlWrKt5/99136+KLL57TXP/0T//0wPf927/92wPjTz/9tP7xH/9xTl9Lkj75yU/q05/+9Jw/rxTBdJqYhZXn0s2GlcZTiD+uQHYMDYUV6XImJ8P9ANTQpm2HHXaYhoeH9Ytf/KLqz5ktmN61a5defPFF3XPPPZqo1Ae9Bps3b9bv/u7vSqpPMF0vBNNIFP64AtkxNjZ10VxqYiLU0gWgkObZ13fw/qhoH1VfX7i/RoceeqjWrFmjgdJKYZL27t2rCy64QKeddpouvPBCPfLII/r2t7+t2267TVdeeaWWLl2qPXv2TPu8LVu26NJLL9Xb3va2Ax0NJelrX/uaTj75ZJ155pkaHh4+MP7JT35Sl112mc4991y9+tWv1vDwsD760Y9qyZIlWr58uZ5//nlJ0vnnn6/R0VFt2rRJzzzzjJYuXar3vve92rRpk/bs2aOlS5fqyiuvlCRde+21esMb3qDTTjtNn/jEJw58r7/5m7/Ra1/7Wi1btkw/+tGPaj5vxQimkSj8cQWyo6sr5EiX094emlIA0MFN26KAuo5N2z70oQ/ppptu0q9+9auDxj/84Q/rsssu03333af3vve9uuKKK/TmN79Zl1xyia699lrt3LlTJ5100rSvNzQ0pFWrVuk973mPtmzZIkl69tlndfnll+srX/mKduzYoccff/ygz9mzZ4/uuusu3XbbbXrf+96n3/u939P999+vI444Ql/96lcPeuzVV1+tI444Qjt37tRNN92kq6++WieddJJ27typa6+9VrfffrvGxsb03e9+Vzt37tSOHTv0zW9+Uzt27NDNN9+snTt3atu2bfqv//qveZ23CBsQkSjRH9dyATV/XNHKsrjptr8/bDYsp60t3A9ADW/a9tKXvlTvf//7dd111+mII444MP6d73znwArypZdeqo9+9KOzfq3R0VG94hWv0MKFC9XZ2ak/+ZM/0ZNPPqlHHnlEixYtUldXlyTpfe97n66//voDn3fRRRdpwYIFWrJkiV588UUtX75ckrRkyRLt3bt3Tj/P7bffrttvv11nnHGGJGl8fFxjY2PK5/NauXKljjzySEnSJZdcMqevWwkr00iU/v7wR7Qc/rgirWYr/ZbVTbe5XKjakctNrVC3t0+N0ya5epQXzIAGN21bt26dbrjhhnnnOG/ZskU//OEPdeKJJ+qkk07Sr3/9a335y1+e9fMOO+wwSVJbW5sWLFggK/xcbW1teuGFF+Y0B3fXxz72Me3cuVM7d+7U7t27tbqBrSMJppEo/HFFq5ktUM76pttly6T9+8NC26ZN4bh/P2Xx5iKrF2OZ0+CmbUcffbTe/e5364Ybbjgw9uY3v1k333yzJOmmm27SueeeK0nK5XLKl7lim5yc1Be/+EXdf//92rt3r/bu3atbb71VW7Zs0cknn6y9e/ceyLGO0j9qtWDBggO51KXz+f3f/3197nOf03jhBfTRRx/VE088ofPOO08jIyN65plnlM/n9ZWvfGVec4iQ5oHEif64Dg2FHOnFi8OKNIE00qY4UI5EAfOKFVPP89k23TZwQSUROjqa8zO2YipNNc8xXjtbQGmO9MDA1G2pbivUH/nIR/QP//APB27//d//vT7wgQ/o2muv1bHHHqvPf/7zkqRVq1bp8ssv13XXXadbbrnlQN70Pffco87OTv3O7/zOga9x3nnn6cEHH9RTTz2l66+/Xm9/+9t15JFH6txzzy0bkFdrzZo1Ou2003TmmWfqpptu0jnnnKPXv/71uuiii3Tttddq165dOvvssyVJHR0d+rd/+zedeeaZ6u/v1+mnn65XvvKVesMb3lDz9y9mnuKued3d3T46Ohr3NACgrM2bwyphpT0Ag4PSj38cVhMr2bRJuuqqxs0xK8o1h2lrS39zmGqeY61+MZZmu3bt0imnnDL7A7duDVU7inOkiwPs4eGWadqWFOV+N2a2w927Sx/LyjQANEg11WnYdNt4rbx6SwWkjIiatvX2Tm/a1tPTMk3b0oqcaQBokGpKv7HptvFauX495QUzIgNN29KMYDpODexoBCB+1QTKbLptvFZeveViDIgfwXScGtjRCED8qg2UqWjRWK28esvFWPqlee9aq5rr74QNiHGaaXdunQqxA4jf+DjVaeKUz4dSceUKB+Ry6c6ZjvAcS6eHHnpIuVxOxxxzzIG6yoiXu+uXv/yl8vm8Fi1adNB9lTYgEkzHrTigjhBIA0BdtWo1D6Tb888/r3379unZZ5+Neyoocvjhh+uEE07QggULDhonmE4y94OT3iYnCaQBoM5YvQUwH5TGS6pKHY1YmQaAumpWcxgA2cIGxDiV5kxPTobj4GBdW4QCAACgMViZjtPIyPTNhgMD4b7BwVCInY5GAAAAiUUwHSc6GgEAAKQawXScos5F1Y4DAAAgUciZBgAAAGpEMA0AAADUiGAaAAAAqBHBNAAAAFAjgmkAAACgRlTzAACkSj4f2oKPjUldXaEteC4X96wAZBXBNAAgNbZvl1asCA1jJyak9nZpwwZp2zZp2bK4Zwcgi0jzAACkQj4fAul8PgTSUjhG4+Pj8c4PQDYRTAMAUmFoKKxIlzM5Ge4HgGYjmAYApMLY2NSKdKmJCWn37ubOBwAkcqYBACnR1RVypMsF1O3t0uLFzZ9TK2BDJzA/5u5xz6Fm3d3dPjo6Gvc0AABNkM9LnZ3hWCqXk/bvlzo6mj+vNCu3obOtjQ2dQDlmtsPdu0vHSfMAAKRCLheCvFwuBH1SOEbjBNJzw4ZOoD5I8wAApMayZWEFemgo5EgvXhzSEgik566aDZ2rVzd3TkAaEUwDAFKlo4Mgrx7Y0AnUB2keAABkULShsxw2dALVI5gGACCD+vvDZsNy2trC/QBmRzANAEAG5XLS1VeXv+/qq8lDB6pFMA0AQAbl89KmTeXv27SJah5AtQimAQDIINqzA/VBNQ8AABog6Z0FqeYB1AfBNAAAdVaus+CGDcnqLEh7dqA+YknzMLO1ZvaAmf3AzNYVxo42szvMbKxwfHkccwMAYD7S0lmQah5AfTQ9mDaz10u6XNIbJZ0u6WIzWyxpk6Q73b1L0p2F2wAApEpacpFpzw7URxxpHqdIutfdfyNJZvYNSX2S3iHp/MJjbpR0t6SNMcwPAICapSkXmfbswPzFEUw/IOlvzOwYSc9IWiFpVNJx7v5Y4TGPSzouhrkBADAnpRsNX/WqdOUi054dmJ+mB9PuvsvMPiXpdkkTknZKerHkMW5mXu7zzWyNpDWStHDhwgbPFgCAysptNDSrnOZBLjLQemLZgOjuN7j7We5+nqSnJP1Y0s/M7HhJKhyfqPC517t7t7t3H3vssc2bNIB5y+elzZuljRvDMZ+Pe0ZA7SptNBwfDwF1Rwe5yEAWxFIaz8xe6e5PmNlChXzpN0laJOkySVcXjrfGMTcAjZGGUmHAXMy00dAstOQ+/HBykYFWF1ed6S8Xcqafl/Qhd3/azK6W9EUzWy3pYUnvjmluAOqseAUvEq3krVgRNkARZCBtZttouG+fdNVVzZ0TgOaLJZh293PLjP1S0oUxTAdAg1VTKowNUEgbmp6gnpLeMROV0QERSIBWfxFNU6kwoFr9/SFVqRw2GmIuSINLN4JpIGZZeBFlBQ+tKNpQWPr/t62NjYaoHmlw6RdLNQ8AQVraDs8XbYvRqqKmJ4OD0qZN4bh/f+tcCKPx0tIxE5WxMg3EKCu5xKzgoZXR9ATzQRpc+hFMAzHK0osobYsBYDrS4NKPYBqIUdZeRFnBA5A1s20wZyNr+pl72a7dqdDd3e2jo6NxTwOoWT4vdXaW7wSYy7HxBGg1rV65Bwcrt8E8Sm8rzquv9nGIl5ntcPfuaeME00C8eBEFsoH/69ky18WS8XHS4JKuUjBNmgdaUppWf8glBlof5c+yZ64bzEmDSy+CabScNNZt5kUUaG1ZqdyDKVnaYJ51BNNoKaz+AEgiAqvsydoG80rS9E5xrWjagpZC8XsASRQFVuVkKbDKEppVhXeKOzuldeuka64Jx87OMN5KCKbRUlj9QRzyeWnzZmnjxnAst+EI2UZglT1Rs6pcbupCqr19arzV3yXNSodfiTQPtBjeVkOzpTFHH81HF9BsyvIG8yztEyCYRkuh+D2aiRx9zEWWA6ssy+oG8yy9U0wwjZbC6g+aKUsrL6iPrAZWyJ4svVNMMI2Ww+oPmiVLKy+YmyxUMABmkqV3igmm0ZJY/UEzZGnlZb6yFFySRw9k651i2okDQI3m2i44q7LURpvnBHCwVmqTTjtxAKizLK281CprmzTJowcOloV3igmmAWAeyNGfWdaCS/LogewhmAaAecrCykutWjW4rJQDTh49kD0E0wCAhmnF4HKmDYZZqmAAIKCdOACgYVqtjfZsLZLNst1CGsgiVqYBAA3Taps0q80BJ48eyA6CaQBAQ7XSJs1qc8DJoweyg2AaANBwrRJctmIOOID5IWcaAIAqtVoOOID5I5gGAKBKUQ44GwwBREjzAABgDlopBxzA/BFMAwAwR62SAw5g/kjzAAAAAGpEMA0AAADUiGAaAAAAqBHBNAAAAFAjgmkAAACgRgTTAAAAQI0IpgEAAIAaEUwDAAAANSKYBgAAAGpEMA0AAADUiGAaAAAAqBHBNAAAAFAjgmkAAACgRofGPQEAQP3k89LQkDQ2JnV1Sf39Ui4X96wAoHURTANAi9i+XVqxQpqclCYmpPZ2acMGads2admyuGcHAK2JNA8AaAH5fAik8/kQSEvhGI2Pj8c7PwBoVQTTANAChobCinQ5k5PhfgBA/RFMA0ALGBubWpEuNTEh7d7d3PkAQFbEEkyb2Xoz+4GZPWBmW8zscDNbZGb3mtluMxsys5fEMTcASKOurpAjXU57u7R4cXPnAwBZ0fRg2sw6JV0hqdvdXy/pEEmrJH1K0oC7L5b0lKTVzZ4bAKRVf7/UVuEVva0t3A8AqL+40jwOlXSEmR0q6UhJj0m6QNIthftvlNQb09wAIHVyuVC1I5ebWqFub58a7+iId34A0KqaXhrP3R81s09LekTSM5Jul7RD0tPu/kLhYfskdTZ7bgCQZsuWSfv3h82Gu3eH1I7+fgJpAGikpgfTZvZySe+QtEjS05K+JGn5HD5/jaQ1krRw4cJGTBEAUqujQ1pNkhwANE0caR5vkfSQu//c3Z+XNCzpHElHFdI+JOkESY+W+2R3v97du929+9hjj23OjAEAAIAy4gimH5H0JjM70sxM0oWSHpT0dUnvLDzmMkm3xjA3AAAAoGpND6bd/V6FjYbfk3R/YQ7XS9ooaYOZ7ZZ0jKQbmj03pJi7tHVrOFYzDgAAUAexVPNw90+4+8nu/np3v9Tdn3P3n7j7G919sbu/y92fi2NuSKmREamvT1q/fipwdg+3+/rC/QAAAHXW9A2IQEP09kpr10qDg+H2wEAIpAcHw3gvlRaBrMnnQ2WTsbHQ1Ka/P5QKBIB6Mk/x29/d3d0+Ojoa9zSQFNFKdBRQSyGQHhiQzOKbF4Cm275dWrFCmpwM7dTb20Pzmm3bQglBAJgrM9vh7t3TxgmmW4B7SGPo7T04aKw03srcD24DNzmZnZ8dmcdKbJDPS52d4Vgqlwu1uKm9DWCuKgXTcXVARD2RLxxEP3Ox4nMCtLDt20MAuW6ddM014djZGcazZmgoXEeXMzkZ7geAeiGYbgXF+cJR8Ji1fOHSn3lycvo5AVpUPh9SGvL5kNIghWM0Pj4e7/yabWxs6jyUmpgI3SEBoF7YgNgKzEJesBSCxyhnOEv5wiMjU4F09DMXn5OeHmnlynjnCDRINSuxWeqK2NUVcqTLBdTt7aHNOgDUCyvTraI4eIxkJZCWwur78PDBP3N0ToaHs7E6j8xiJfZg/f0Hb50o1tYW7geAeiGYbhVZzxc2CyvPpRcPlcaBFhKtxJaTxZXYXC5U7cjlps5Le/vUOJsPkSX5vLR5s7RxYziW25iL+aGaRysozRcurbGcpRVqIIOoXlHe+HhIcdm9O1xQ9Pdn8zwguygRWV+UxmtlW7eGqh3FgXNxgD08TL4w0OL4owmgGBfZ9VcpmGYDYiuI8oWL60lH+cI9PeQLAxmwbFn448hKLACJjcnNRDDdCqK84GrHAbSkjg7+OCIeNAxKHjYmNw/BNAAAqFm5FKMNG0gxihslIpuHah4AAKAmNAxKLkpENg/BNJrLPWyYLN34WmkcAJBYtG5PLkpENg9pHmiukREqj8SM3MbqcJ6A2ZGXm2xsTG4Ogmk0V29vCKSjluelNbGpPNJQ5DZWh/MEVIe83ORjY3LjUWcazVe8Eh2huUzDUXO0OpwnoHr8f0GWVKozTc40mi+qgV2MQLrhyG2sDucJraBZLaTJywVI80gn95B7XNykZabxpIlWpoutX09A3WDkNlaH84S0a3aaEnm5yDpWptMo2sS3fv1U9YsoQO3rC/cnVXGKx9q14dU+yqEu/nlQd1FuYznkNk7hPCHN4ipVF+XlXnVVOBJII0sIptOoeBNfFICmZRPfyMjUPKOV6IGBqZ8nyRcCKUfN0epwnpBmpCkBzUeaRxoV5xwPDk5t5EvDJr7e3lD+rjgVJfp5enqSfSGQclEOY+nbv21t5DYW4zwhzUhTApqPah5p5n7wEtrkZLIDaSTC+Di5jdXgPCGNNm+W1q2rXKpucJAyaUCtKlXzIJhOK8rLAQBKUKoOaBxK47USNvEBAMqotlRds0rnAVlAznQaVdrEJ4Xxnh5acgNARs1Wqo4On0B9keaRRmmvMw0AiAVpIEDtSPNoJWZh5bk0YK40DgCAKJ0HNALBNAAAGUHpPKD+CKYBAMgIOnwC9UcwDQB1RJUEJBkdPoH6I5jOGndp69bp5fMqjQOo2vbtYXPXunXSNdeEY2dnGAeSoNrSeQCqR2m8rBkZkfr6Di6rV1y3eniYsnpADfL5UG6seCU6yk1dsWKqSkI+HzZ5jY2Ft9z7+0MgAzTLbKXzAMwNwXTW9PZONXiRQkBd3ACmtzfe+QEpVU2VhNe9jvq+SIaODtqKA/VCMJ01pQ1eoqCaVuTAvMxWJeHBB8N162wr1wCA6ZL8rh4501lUHFBHCKSBeZmtSsIvfkF9XwCoRdL3oxBMZ1GUI11s/Xo2HwLzMFuVhKOPpr4vAMxV8X6U6DV0YmJqfHw83vlJBNPZU7zZcO3asCQW5VATUAM1m61KwqmnUt8XAOYqDV07yZnOmpGRqUA6Su0ozqHu6aGaB1CjmaoknH562GxYDvV9AaC8NHTtJJjOmt7eUP6ut3cqRzoKqHt6qOYBzFOlKgnRCnVpNY+2Nur7AkAl0X6UcgF1Ut7VM0/x2/rd3d0+Ojoa9zQAoGrj49T3BYBq5fNhs2G5brK5XHMrIZnZDnfvLh1nZRrJ4B5SUIpXzGcaB1KK+r4AUL00vKvHBkQkQ9SZsXgTZLRZsq8v3A8AADIn2o8yOCht2hSO+/cnp9kVK9NIBjozAgCACpL8rh7BNJKBzowAACCF2ICIZHE/uPPF5CSBNIDMSXLrZCCrKm1AJGcayUFnRgBIfOtkAAcjmEYy0JkRAFLROhnAwZoeTJvZ68xsZ9G/X5vZOjM72szuMLOxwvHlzZ4bYlSpM2MUUFPNAxmRz0ubN0sbN4ZjudqqaF1paJ0M4GBN34Do7j+StFSSzOwQSY9K2ippk6Q73f1qM9tUuL2x2fNDTOjMCGj79um1VDdsCLVUk1ICKusancuchtbJWUYuO8qZNZg2syMlfUTSQne/3My6JL3O3f+9Dt//Qkl73P1hM3uHpPML4zdKulsE09lhJq1cWf040GKK396PREHVihXN7fKF8ppxsZOG1slZxcUuKqkmzePzkp6TdHbh9qOS/ledvv8qSVsKHx/n7o8VPn5c0nF1+h4A6oD0g8bi7f1ka1Yuc3//wQWNirW1hfvRfOSyYybVBNMnufs1kp6XJHf/jaR51yozs5dIukTSl0rv81Cvr+yOMzNbY2ajZjb685//fL7TAFAFqgs0Hm/vJ1uzLnai1sm5XFj5lMIxGufdiXhwsYuZVJMz/VszO0KF4NbMTlJYqZ6viyR9z91/Vrj9MzM73t0fM7PjJT1R7pPc/XpJ10uhznQd5gFgBqQfNAdv7ydbMy92otbJQ0Ph6y5eHFak+X8WHy52MZNqgulPSPqapFeZ2U2SzpH0x3X43u/RVIqHJN0m6TJJVxeOt9bhewCYp2pWZJLa4jVN+vtD/mU5vL0fv2Zf7FRqncwGuHhwsVubrDxfZ+yAaGZtkt4p6U5Jb1JI7/hPd//FvL6pWbukRyS9xt1/VRg7RtIXJS2U9LCkd7v7kzN9HTogAo23cWNI7fToQDkAACAASURBVKhk0ybpqquaN59WVm6DU1sbG5ySIJ8PqU3l9grkcs15h4bnR3yS8PtPm/k+X5MYiFfqgDjjyrS7T5rZR939i5K+Wq/JuPuEpGNKxn6pUN0DQIKwItM8vL2fXFHOcqXgoNG/I9Kt4hX37z9t5vt8TVvllBlXpiXJzK6W9AtJQ5IO/DmdbdW4GViZBhqPFRlgyvh4PBc7mzeHjb+VLmoHB0m3aoa4fv9pM5/na5L/5tS0Ml0QZep9qGjMJb2mHhMDkGysyABTKuUyNxob4JIhrt9/2szn+ZrGfTqzBtPuvqgZEwGQXKQfAPEi3QppMp/naxovHKvpgLhA0l9IOq8wdLek/+PuzzdwXgAShhUZID5Ue0GazOf5msYLx2qatvyTpLMk/WPh31mFMQAA0AQ0c0GazOf5msYuoNXkTL/B3U8vun2XmX2/URMCAADTkW6FNKn1+ZrGfTrVBNMvmtlJ7r5HkszsNZJebOy0AABAKdKtkCa1Pl/TduFYTTB9paSvm9lPFJq2vFrSBxo6KwAAAGRWmi4cq6nmcaeZdUl6XWHoR+7+XGOnBQAAACTfrBsQzexDko5w9/vc/T5JR5rZBxs/NQAAACDZqqnmcbm7Px3dcPenJF3euCkBAAAA6VBNMH2ImVl0w8wOkfSSxk0JSBh3aevWcKxmHMiQfD60Dt64MRzLtQAGgFZWTTD9NUlDZnahmV0oaUthDMiGkRGpr09av34qcHYPt/v6wv1ABm3fLnV2SuvWSddcE46dnWEcALKimmoeGyWtUeiCKEl3SNrcsBkBSdPbK61dKw0OhtsDAyGQHhwM47298c4PiEE+H+rAFq9ERx3LVqwIZa2SWsYKAOqpmmoek5I+a2afk3SqpEfdnTrTyA6zEEBLIYCOguq1a8P4VBYUkBlDQ6GhQjmTk+H+tJS1AoD5qJjmYWafNbNTCx+/TNJOSf8q6b/N7D1Nmh+QDMUBdYRAGhk2Nja1El1qYiI0WgCyhP0D2TVTzvS57v6DwscfkPRjd18i6SxJH234zIAkiXKkixXnUAMZ09UVWvyW094eOpYBWcH+gWybKZj+bdHHb5U0Iknu/nhDZwQkTRRIRznSk5NTOdQE1Mio/n6prcJfkLa2cD+QBcX7B6J3ayYmpsbHx+OdXzFWzxtjppzpp83sYkmPSjpH0mpJMrNDJR3RhLkByTAyMhVIR6kdxTnUPT3SypXxzhFoslxO2rYtBAuTkyF4aG8PgfS2bWw+RHakZf/A9u3T/79u2BD+vy5bFvfs0m2mYPrPJF0n6X9IWle0In2hpK82emJAYvT2SsPD4RjlSEcBdU8P1TyQWcuWhaodQ0MhR3rx4rAiTSCNLEnD/gGq7zRWxWDa3X8saXmZ8f+Q9B+NnBRagHtY0S0OQGcaTzKz8ivPlcZRN/l8CNTGxkKObn9/WBFFcnR0JGPVDYhLtH+gXECdlP0DaVk9T6tqmrYAc0ejE8wTG3oApEEa9g+kYfU8zQim0RjFjU6igJpGJ6hSmjb0AMi2aP9ALjdV4aa9fWo8CekTVN9prGo6IAJzR6MTzANvSQJIk6TvH+jvD5sNy0nK6nmazRhMm9nJkjol3evu40Xjy939a42eHFIuCqijQFoikEZVeEsSQNokef8A1Xcaa6YOiFdIulXShyU9YGbvKLr7bxs9MbQAGp2gRrwlCQD1Fa2eDw5KmzaF4/79lMWrh5lWpi+XdJa7j5vZiZJuMbMT3X1QEkuLmFlpjvTAwNRtiRVqzIi3JAGg/pK8ep5mMwXTbVFqh7vvNbPzFQLqV4tgGrOh0QnmgbckAQBpYV7hLXczu0vSBnffWTR2qKTPSXqvux/SnClW1t3d7aOjo3FPA+W0Up1pxGZ8PLkbegAA2WJmO9y9e9r4DMH0CZJeKOp8WHzfOe7+rfpPc24IpgEAANAMlYLpmTog7pvhvtgDaQAAACBuNG0BMDt3aevW6ZVYKo0DAJARBNMAZkd7eAAAyqq6A6KZvbT48e7+ZENmBCB5itvDSweXOqQ9PAAgw2YNps3szyT9taRnJUXv5bqk1zRwXgCShPbwAACUVbGax4EHmI1JOtvdf9GcKVWPah5Ak7mHYs+RyUkCaQBAJlSq5lFNzvQeSb+p/5QApArt4QEAmKaanOmPSfq2md0r6blo0N2vaNisACQL7eEBACirmmD6/0i6S9L9kiYbOx0AiUR7eAAAyqommF7g7hsaPhMAydXbKw0PH9wGPgqoe3qo5gEAyKxqcqb/r5mtMbPjzezo6F/DZwYgOczCynNpKkelcQAAMqKalen3FI4fKxqjNB4AAAAyb9Zg2t0XNWMiAAAAQNpU1QHRzF4v6XclHR6Nufu/NmpSAIDkyeeloSFpbEzq6pL6+6VcLu5ZAWg1aXutqaZpyyckna8QTG+TdJGk7e7+zobPbhY0bQGazD1U9ijeiDjTOFrG9u3SihWhT8/EhNTeHvr3bNsmLVsW9+wAtIokv9bMp2nLOyVdKOlxd/+ApNMlvazO8wOQBiMjUl/fwc1aohrUfX3hfrScfD78ccvnwx83KRyj8fHxeOcHoDWk9bWmmmD6GXeflPSCmb1U0hOSXtXYaaFq7tLWrdO70FUaB+ajtzfUmh4cnAqoi5u5UCKvJQ0NhVWiciYnw/0AMF9pfa2pJpgeNbOjJP2zpB2SvifpOw2dFarHSiGaKaotHQXUbW3Tm7mg5YyNTa0SlZqYkHbvbu58ALSmtL7WzBpMu/sH3f1pd/+spLdKuqyQ7oEkYKUQzVbc/TBCIN3SurpC3mI57e3S4sXNnQ+A1pTW15pZg2kzWx197O57Jf2gsCmxZmZ2lJndYmY/NLNdZnZ2oRnMHWY2Vji+fD7fIzNYKUSzRRdsxYrfGUHL6e8PLy3ltLWF+wFgvtL6WlNNmseFZrat0AHxVEn/KWm+BUoGJX3N3U9W2NC4S9ImSXe6e5ekOwu3UQ1WChFpdA596Tsfk5PT3xlBy8nlwk76XG5q1ai9fWq8oyPe+QFoDWl9rammacsfmVm/pPslTUj6I3f/Vq3f0MxeJuk8SX9c+Pq/lfRbM3uHQgk+SbpR0t2SNtb6fTKl0kohAXX2RDn0xe9MFAfAw8Oh/fd8vn7pOx/RhdzgoNTTM7+vj8Ratkzavz9sANq9O7zd2t+f3D9uANIpja811dSZ7lIIbu+XdIqkByVtcPff1PQNzZZKur7wdU5X2NS4VtKj7n5U4TEm6anodiXUmdb0lcKBgem3Caizo9HPhxTWmU5b8X8AQDJVqjNdTTD9Q0kfcvc7C0HuBkl/4u6n1jiRboVUkXPc/V4zG5T0a0kfLg6ezewpd5+WN21mayStkaSFCxee9fDDD9cyjdaxdWtjVyKRPsW//0hGL6ySXPwfAJAu8wmmX+ruvy4Ze627/7jGifwPSf/p7icWbp+rkB+9WNL57v6YmR0v6W53f91MX4uVaaVypRBN4H7wLo7Jycw9D/J5qbMzHEvlcuFtxCS/bQgASJY5d0A0s49Kkrv/2szeVXL3H9c6EXd/XNJPzSwKlC9USPm4TdJlhbHLJN1a6/fIFLOw8lwaKFUaR+uj2oak9Bb/BwCky0zVPFYVffyxkvuWz/P7fljSTWZ2n6Slkv5W0tWS3mpmY5LeUrgNYC6otnFAWov/AwDSZaZqHlbh43K358Tdd0qatkyusEoNoFZU2zggKv5fLqBOcvF/AEC6zLQy7RU+LncbQBL09oZNp8WbDaOAeng4Ux0x01r8HwCQLjOtTJ9uZr9WWIU+ovCxCrcPb/jMAMxdlCtf7XgLi4r8V6rmweZDAEA9VAym3f2QZk4EAOotjcX/AQDpMmsHRABIs44OafXquGcBAGhVM+VMAwAAAJgBwTQAAABQI4JpAAAAoEYE0wAAAECN2IAIAABSI58PFXrGxkJzpv7+UAoTiAvBNAAASIXt26fXjt+wIdSOX7Ys7tkhq0jzAAAAiZfPh0A6nw+BtBSO0fj4eLzzQ3YRTAMAgMQbGgor0uVMTob7gTgQTANz5S5t3RqO1YwDAMrK56XNm6WNG8Mxn6/82LGxqRXpUhMTocspEAeCaWCuRkakvj5p/fqpwNk93O7rC/cDAGa0fbvU2SmtWyddc004dnaG8XK6ukKOdDnt7dLixY2bKzATgmlgrnp7pbVrpcHBqYB6/fpwe+3acD8AoKJa8p/7+6W2ClFLW1u4H4gDwTQwV2bSwMBUQN3WNhVIDwyE+wEAFdWS/5zLhaodudzUCnV7+9R4R0fj5gvMhNJ4QC2igHpwcGqMQBoAqlJr/vOyZdL+/SHY3r07pHb09xNII14E00AtotSOYuvXE1ADQBWi/OdyAfVs+c8dHdLq1Y2bGzBXpHkAc1WaIz05OT2HGgBQEfnPaCUE08BcjYxMz5EuzqGmmgcAzIj8Z7QS8xSvonV3d/vo6Gjc00DWuIeAubf34JSOSuMAgLLGx8l/RnqY2Q537542TjANAAAAzKxSME2aBwAAAFAjgmkAAACgRgTTAAAAQI0IpgEAAIAaEUwDAAAANSKYBgAAAGpEMA0AAADUiGAaAAAAqBHBNAAAAFAjgmkAAACgRgTTAAAAQI0OjXsCAIBsyueloSFpbEzq6pL6+6VcLu5ZAcDcEEwDAJpu+3ZpxQppclKamJDa26UNG6Rt26Rly+KeHQBUjzQPAEBT5fMhkM7nQyAthWM0Pj4e7/wAYC4IpgHEx13aujUcqxlHSxgaCivS5UxOhvsBIC0IpgHEZ2RE6uuT1q+fCpzdw+2+vnB/FmTsomJsbGpFutTEhLR7d3PnAwDzQTANpFUrBGC9vdLatdLg4FRAvX59uL12bbg/CzJ2UdHVFXKky2lvlxYvbu58AGA+CKaBtGqFAMxMGhiYCqjb2qYC6YGBcH8WZOyior8//KrLaWsL9wNAWpinYfWqgu7ubh8dHY17GkA8SgOugYHpt9MSjLofHF1NTqZn7vVS/PuMpO33OAflqnm0tVHNA0BymdkOd++eNk4wDaRYKwRgrfAz1EvGLirGx8Nmw927Q2pHf7/U0RH3rACgvErBNGkeQJpFaRLF0hSElq6uT05OT3fIiuhcFGvxc9DRIa1eLV11VTgSSANII4JpIM3SHoCNjExPSynOoU5D3nc9cFEBAKlFMA2kVSsEYL290vDwwavpUUA9PNxyG+8q4qICAFKLnGkgrbZuDVU7igOw4gB7eFhauTLuWaIa7iFg7u09OEWn0jgAoOnYgAi0GgIwAACahg2IQKsxCyvPpQFzpXEkSys03QEAEEwDQCxaoekOAECHxvFNzWyvpLykFyW94O7dZna0pCFJJ0raK+nd7v5UHPMDgIYr7nooTW+6k5XNlwCQcnGuTP+euy8tyj3ZJOlOd++SdGfhNoB6IKUgeWilDgAtIUlpHu+QdGPh4xslJWtZhmAEaUZKQTKlvekOACC2YNol3W5mO8xsTWHsOHd/rPDx45KOi2dqFRCMIM2KUwqi5zApBfFLe9MdAEA8OdOSlrn7o2b2Skl3mNkPi+90dzezsn9NCsH3GklauHBh42caIb8RaVa8Ajo4OPU8JqUgPqUXNMWvKRK/FwBIidjrTJvZJyWNS7pc0vnu/piZHS/pbnd/3Uyf2/Q608V//CIEI0gT95CbG5mc5LkbF5ruAECqJKbOtJm1m1ku+ljS2yQ9IOk2SZcVHnaZpFubPbdZkd+INHOX1q07eCxKKSD3v/lopQ4ALSGONI/jJG218MfjUElfcPevmdl/Sfqima2W9LCkd8cwt5lVym8koEbSRc/d664Lt6+4IhwHB6cC6OuuYzW0maLmOtWOAwASqenBtLv/RNLpZcZ/KenCZs+nauQ3Is1GRsJzNQqir7sufHzFFVMBNrn/AADMWVwbENMnCkaK8xuLN3T19LCahOSKUgqiYNns4Nz/K67gghBAU+Tz0tCQNDYmdXVJ/f1SLhf3rIDaxb4BcT6augHRPQTUvb0HBxyVxoEkYyMigBhs3y6tWBFeciYmpPb28FK0bZu0bFncswNmlpgNiKkV5TGWBhyVxoGkorYxgBjk8yGQzudDIC2FYzQ+Ph7v/IBaEUwDWVKa+z85Ob2ZCwA0wNBQeMkpZ3Iy3A+kETnTQJaQ+w8gJmNjUyvSpSYmpN27mzsfoF4IpoEsKd6IWFrbuKeHah5AzFp5c15XV8iRLhdQt7dLixc3f05APbABEQCABGj1zXn5vNTZGY6lcjlp/36po6P58wKqxQZEAAASKgub83K5cGGQy4ULBSkco3ECaaQVwXQrq9QimtbRAJAoWdmct2xZWIEeHJQ2bQrH/ftbY+Ud2UUw3cpGRqS+voOrNETVHPr6wv1AKS7CgKbL0ua8jg5p9WrpqqvCkRVppB3BdCvr7Z1e9qy4LBqbzVAOF2GoFRdiNYs255XD5jwg2QimW1lUpSEKqNvappdFA0pxEYZaZfxCLJ+XNm+WNm4Mx3Ib7Srp7z+4KWmxtrZwP4BkoppHFtA6GnNVHEBHuAjDbEovvAYGpt9u0edPPSpxtHo1DyDtKlXzIJhudQRFqBUXYahFBl9z6lnybXw8bDbcvTukdvT3k1MMJAWl8bKI1tGoVfTcKcZzBtUo7qoZaeFAWqpvJQ425wHpQzDdyiq1jo4C6hbPX0SVSjeHFV+Evf3t0osvchGG6mXwQixLlTgATEcw3cqi1tHFq0JRQB21lAZKN41FF2FLl0pf/ap0661chKE6GX03jEocSKv5bJrFFHKmgawrDYD+9/+WLrkkBNLF72pEgXZvb0u/ZY952Lo1XJiVPm+i59fwsLRyZdyzrDvaZCON2PA6d2xABFBZBjeNoQEqXXBl4EKMwARSuKAaGgqpP11dYQNpLhf3rKbjArA2BNMAZkb1DmBeqMSRbWm6oNq8WVq3rnyuf3t7WFdZvbr580q6SsH0oXFMBkDCVNo0xso0ULWoEgeyJ58PgXTxSm8UqK5YkbyVXjbN1hcbEIGsy+imMQBsQKuXepZHbAY2zdYXK9NA1lUqoSiF8Z6eltw0BmRdubSEDRuSmZaQdGlb6e3vD7/rcmhfP3esTANZRwlFIHOK0xKiIHBiYmp8fDze+aVN2lZ6c7lw0ZTLTc27vX1qPEkpKWlAMJ1WpY02ZhsHKjELK8+ludGVxgGkXtrSEpKuv//g/dvFkrrSu2xZyOUeHJQ2bQrH/ft5V6IWBNNpVdpoQ5rKfe3ro7EGAKCitKUlJF1aV3ppX18f5EzPRZJqqPb2Tm0Sk8Jb8sWbyHhrHgBQQZSWUKk0WtLSEtIgWumlPGL2UGd6LpLW3YtGGwCAGtC0A5i7SnWmSfOYi+LV4Ci9Is7V4OKqCxECaQDALJKclkC5PqQNaR5zUVoyLFoRnu9qcK3pIzTaAADUKIlpCa1ari8tbcZRG9I8alHvtsu1pI+UroqX5kwTUAMAUqRVU0/S1GYcMyPNo14qrQbP56KklvSRSo02oq9DNQ8AQIq0Yrk+6nlnA8H0XDSq7XJpINzWNvsKM402AMSJWveos1Ys19eKFwiYjmB6Lhq5GjzXzYQ02gAQJ2rdQ6rrRVXaughWoxUvEDAdwfRcNHI1uBHpIwCaJ2srtUmrboR41PGiKo1dBGfTihcIKMPdU/vvrLPO8pYwOem+dq27FI7lbgNItuHh6f9ni/8vDw/HO79GKP75on+8ZmVLnf9+3XOPey7n3t4evkR7e7h9zz0Nmn+D/frXYf7F/0Wif7mcez4f9wwxF5JGvUw8SjWPJEhaMxgAc5fVCjv1rm6E9KlzA7Hx8WSV65svqnm0jkrVPAimkyBJbcoB1C5rXUmz9vOiMi6qZtRqFwhZRTANAM2QlaAiqyvxmI6LKmQEdaYBoNGytJGYWveQGlcyFkgRgmkAqIesBRXUus9eBZdyuKgCSPMAgLpgI3H28Dtnzw8yhTQPAGikVlypZeV1ZtTapoEYIIJpAKiPVgwq6HI4s9KUhrY2NmACGUQwDQAoj5XX2UUBdTECaSBTCKYBAOWx8jq7LFVwqYR0IGQcwTQAoDJWXivLWgWXSkgHQsYRTAMAKmPltTLKwgWkAyHjDo17AgCAhJqpy6HECnVUwaW4/FsUUPf0ZCeILH73YnBw6vlBOhAyIrY602Z2iKRRSY+6+8VmtkjSzZKOkbRD0qXu/tuZvgZ1pgGggaijjLlwD3n1kclJAmm0lCTWmV4raVfR7U9JGnD3xZKekrQ6llkBAIJWrJ2NxiAdCBkWSzBtZidIerukzYXbJukCSbcUHnKjJF6lASBOrVg7G/XHRkxkXFw5038n6aOScoXbx0h62t1fKNzeJ6kzjokBAIA5qLQRUwrjPT2kA6GlNX1l2swulvSEu++o8fPXmNmomY3+/Oc/r/PsAKQCdW2B5CAdCBkXR5rHOZIuMbO9ChsOL5A0KOkoM4tWyk+Q9Gi5T3b369292927jz322GbMF0DSUNcWSA7SgZBxTQ+m3f1j7n6Cu58oaZWku9z9vZK+LumdhYddJunWZs8NQEpQ1xYAkBBJatqyUdIGM9utkEN9Q8zzAZBUtLkGkHWkuyVGrMG0u9/t7hcXPv6Ju7/R3Re7+7vc/bk45wYg4WhzDSDLSHdLjCStTANA9ahrCyDLSHdLDIJpAOlDXVsAWdfodDfSSKpGMA0gfSrVtY3+qPD2JoAsaGS6G2kkVSOYBpA+1LUFgMamu5FGUrW4OiACQO2i+rXVjgNAqykNbgcGpm5L81+hLu1kGX1dqiZNY57inJfu7m4fHR2NexoAAADNtXVrSLcoDm6LA+zh4fosLriHfOzI5GRmA2kz2+Hu3aXjpHkAAACkTTPS3aiaVBWCaQAAgLRpdBt3qiZVjZxpAAAAHKxS1SQpjPf0sEelgGAaAAAAB4vSSHp7p6eR9PRQzaMIwTQAAAAORtWkqpEzDQAAANSIYBoAAACoEcE0AAAAUCOCaQAAAKBGBNMAAABAjQimASSTe2iXW9oYoNI4AAAxIJgGkEwjI1Jf38GdtqKOXH194X4AAGJGnWkAydTbO9W6VgqNAopb29IwAACQAATTAJKptHVtFFQXt7YFACBm5inOO+zu7vbR0dG4pwGgkdyltqKMtMlJAmkAQNOZ2Q537y4dJ2caQHJFOdLFinOoAQCIGcE0gGSKAukoR3pyciqHmoAaAJAQ5EwDSKaRkalAOsqRLs6h7umRVq6Md44AgMwjmAaQTL290vBwOEY50lFA3dNDNQ8AQCIQTANIJrPyK8+VxgEAiAE50wAAAECNCKYBAACAGhFMAwAAADUimAYAAABqRDANAAAA1IhgGgAAAKgRwTQAAABQI4JpAAAAoEYE0wAAAECNCKYBAACAGhFMAwAAADUimAYAAABqRDANAAAA1IhgGgAAAKgRwTQAAABQI4JpAAAAoEYE0wAAAECNCKYBAACAGhFMAwAAADUimAYAYD7cpa1bw7GacQAthWAaAID5GBmR+vqk9eunAmf3cLuvL9wPoGUdGvcEAABItd5eae1aaXAw3B4YCIH04GAY7+2Nd34AGopgGgCA+TALAbQUAugoqF67NoybxTc3AA3X9DQPMzvczL5rZt83sx+Y2V8XxheZ2b1mttvMhszsJc2eGwAANSkOqCME0kAmxJEz/ZykC9z9dElLJS03szdJ+pSkAXdfLOkpSatjmBsAAHMX5UgXK86hBtCymh5MezBeuLmg8M8lXSDplsL4jZJIMgMAJF8USEc50pOTUznUBNRAy4slZ9rMDpG0Q9JiSZ+RtEfS0+7+QuEh+yR1xjE3AADmZGRkKpCOUjuKc6h7eqSVK+OdI4CGiSWYdvcXJS01s6MkbZV0crWfa2ZrJK2RpIULFzZmggAAVKu3VxoeDscoRzoKqHt6qOYBtLhY60y7+9OSvi7pbElHmVkU3J8g6dEKn3O9u3e7e/exxx7bpJkCAFCBWVh5Lt1sWGkcQEuJo5rHsYUVaZnZEZLeKmmXQlD9zsLDLpN0a7PnBgAAAMxFHGkex0u6sZA33Sbpi+7+72b2oKSbzex/SfpvSTfEMDcAAACgak0Ppt39PklnlBn/iaQ3Nns+AAAAQK1izZkGAAAA0oxgGgAAAKgRwTQAAABQI4JpAAAAoEYE0wAAAECNCKYBAACAGhFMAwAAADUimAYAAABqRDANAAAA1IhgGgAAAKgRwTQAAABQI3P3uOdQMzP7uaSHY/jWr5D0ixi+bxZwbhuHc9tYnN/G4dw2Due2cTi3jRXH+X21ux9bOpjqYDouZjbq7t1xz6MVcW4bh3PbWJzfxuHcNg7ntnE4t42VpPNLmgcAAABQI4JpAAAAoEYE07W5Pu4JtDDObeNwbhuL89s4nNvG4dw2Due2sRJzfsmZBgAAAGrEyjQAAABQI4LpGZjZ4Wb2XTP7vpn9wMz+ujC+yMzuNbPdZjZkZi+Je65pZWaHmNl/m9m/F25zbuvEzPaa2f1mttPMRgtjR5vZHWY2Vji+PO55ppGZHWVmt5jZD81sl5mdzbmdPzN7XeH5Gv37tZmt49zWj5mtL/w9e8DMthT+zvG6WwdmtrZwXn9gZusKYzx3a2BmnzOzJ8zsgaKxsufSgusKz9/7zOzMZs+XYHpmz0m6wN1Pl7RU0nIze5OkT0kacPfFkp6StDrGOabdWkm7im5zbuvr99x9aVH5oE2S7nT3Lkl3Fm5j7gYlfc3dT5Z0usJzmHM7T+7+o8LzdamksyT9RtJWcW7rwsw6JV0hqdvdXy/pEEmrxOvuvJnZ6yVdLumNCq8JF5vZYvHcrdW/SFpeMlbpXF4kqavwb42kf2rSHA8gmJ6BB+OFmwsK/1zSBZJuKYzfKKk3humlnpmdIOntkjYXbps4t432DoXzKnF+a2JmL5N0nqQbJMndf+vuT4tzW28XStrj7g+Lc1tPh0o6wswOlXSkpMfE6249G0aL7AAABoBJREFUnCLpXnf/jbu/IOkbkvrEc7cm7v5NSU+WDFc6l++Q9K+FmO0/JR1lZsc3Z6YBwfQsCmkIOyU9IekOSXskPV34zyJJ+yR1xjW/lPs7SR+VNFm4fYw4t/Xkkm43sx1mtqYwdpy7P1b4+HFJx8UztVRbJOnnkj5fSFHabGbt4tzW2ypJWwofc27rwN0flfRpSY8oBNG/krRDvO7WwwOSzjWzY8zsSEkrJL1KPHfrqdK57JT006LHNf05TDA9C3d/sfCW4wkKb9+cHPOUWoKZXSzpCXffEfdcWtgydz9T4S2wD5nZecV3eijlQzmfuTtU0pmS/sndz5A0oZK3bjm381PI2b1E0pdK7+Pc1q6QY/oOhQvC35HUrulvpaMG7r5LIV3mdklfk7RT0oslj+G5WydJO5cE01UqvI37dUlnK7yFcGjhrhMkPRrbxNLrHEmXmNleSTcrvM04KM5t3RRWoeTuTyjknb5R0s+it78Kxyfim2Fq7ZO0z93vLdy+RSG45tzWz0WSvufuPyvc5tzWx1skPeTuP3f35yUNK7wW87pbB+5+g7uf5e7nKeSe/1g8d+up0rl8VOFdgEjTn8ME0zMws2PN7KjCx0dIeqvCRqOvS3pn4WGXSbo1nhmml7t/zN1PcPcTFd7Ovcvd3yvObV2YWbuZ5aKPJb1N4W3I2xTOq8T5rYm7Py7pp2b2usLQhZIeFOe2nt6jqRQPiXNbL49IepOZHVnYoxI9d3ndrQMze2XhuFAhX/oL4rlbT5XO5W2S3l+o6vEmSb8qSgdpCpq2zMDMTlNIcj9E4cLji+7+P83sNQqrqUdL+m9J73P35+KbabqZ2fmS/tLdL+bc1kfhPG4t3DxU0hfc/W/M7BhJX5S0UNLDkt7t7qWbPDALM1uqsHH2JZJ+IukDKrxGiHM7L4WLv0ckvcbdf1UY43lbJxZKvPZLekHhNfZPFfJLed2dJzO7R2Hvz/OSNrj7nTx3a2NmWySdL+kVkn4m6ROSRlTmXBYuDP9BIWXpN5I+4O6jTZ0vwTQAAABQG9I8AAAAgBoRTAMAAAA1IpgGAAAAakQwDQAAANSIYBoAAACoEcE0ADSRmb1oZjuL/m2a/bPq9r0/Z2ZPmNkDMzzmdWZ2d2Fuu8zs+mbNDwDSiNJ4ANBEZjbu7h0xfe/zJI1L+ld3f32Fx/yHpH9091sLt5e4+/3z/L6HuPuLsz8SANKHlWkAiJmZvczMfhR1VTSzLWZ2eeHjfzKzUTP7QaHhRvQ5e83sqsIK8qiZnWlm/2Fme8zsz8t9H3f/pqTZGkYcr9AyPfqc+wvf7xAz+7SZPWBm95nZhwvjF5rZf5vZ/YWV78OK5vcpM/uepHeZ2dvM7Dtm9j0z+5KZxXJBAQD1RjANAM11REmaR3+h09//I+lfzGyVpJe7+z8XHv//unu3pNMk9RQ6s0Yecfelku6R9C8KLaHfJOmvVbsBSXeZ2f81s/VmdlRhfI2kEyUtdffTJN1kZocXvm+/uy9R6Lb5F0Vf65fufqak/0/SxyW9pXB7VNKGecwRABLj0LgnAAAZ80whAD6Iu99hZu+S9BlJpxfd9W4zW6Pwen28pN+VdF/hvtsKx/sldbh7XlLezJ4zs6Pc/em5Ts7dP19I9Vgu6R2S/szMTpf0FkmfdfcXCo97sjD+kLv/uPDpN0r6kKS/K9weKhzfVJj3t0LnX71E0nfmOjcASCKCaQBIADNrk3SKpN9IermkfWa2SNJfSnqDuz9lZv8i6fCiT3uucJws+ji6XfPru7vvl/Q5SZ8rbFYsm19dhYnC0STd4e7vqXVOAJBUpHkAQDKsl7RL0h9J+ryZLZD0UoWA9Fdmdpykixo9CbP/v527x4UwCsMwfD+JTkejVAj2oBdrkEgIOxCdBViCQm0KK5CpEIlOZihohURiA7pX8X2ayVRnYqK4r/b8d0/enHOy069NkhVgGfgAhnRV6oW+bQl4BVaTrPXD94CbKdM+AFu//ZIsJln/25NI0nwYpiVpvibvTJ/1Dw+PgOOqugNugdOqGgGPwAtwCdzPsnCSAd31io0k70kOp3TbBp6TjIBr4KSqPoEL4A0Y9227VfUNHABXSZ7oKuLnkxNW1RewDwySjPs9bM5yFkn6L/waT5IkSWpkZVqSJElqZJiWJEmSGhmmJUmSpEaGaUmSJKmRYVqSJElqZJiWJEmSGhmmJUmSpEaGaUmSJKnRD0KhHG1VOfCXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "positive = data[data['Admitted'].isin([1])]\n",
        "negative = data[data['Admitted'].isin([0])]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "ax.scatter(positive['Exam 1'], positive['Exam 2'], s=50, c='b', marker='o', label='Admitted')\n",
        "ax.scatter(negative['Exam 1'], negative['Exam 2'], s=50, c='r', marker='x', label='Not Admitted')\n",
        "ax.legend()\n",
        "ax.set_xlabel('Exam 1 Score')\n",
        "ax.set_ylabel('Exam 2 Score')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XazehtRqt0tH"
      },
      "source": [
        "看起来在两类间，有一个清晰的决策边界。现在我们需要实现逻辑回归，那样就可以训练一个模型来预测结果。方程实现在下面的代码示例在\"exercises\" 文件夹的 \"ex2.pdf\" 中。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "build model"
      ],
      "metadata": {
        "id": "bZ_U-IHJIUTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim): \n",
        "        super(LogisticRegression,self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim,output_dim)\n",
        "        #  \n",
        "        self.criterion = torch.nn.BCELoss()\n",
        "\n",
        "    def forward(self,x):\n",
        "        y_pred = F.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "    def cal_loss(self, pred, target):\n",
        "        x = self.criterion(pred,target)\n",
        "        return x"
      ],
      "metadata": {
        "id": "UHJMk0EmEqsD"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "initialize model"
      ],
      "metadata": {
        "id": "CPOd1zFLIXIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 200\n",
        "input_dim = 3 # Two inputs x1 and x2 \n",
        "output_dim = 1 # Single binary output \n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "1ppb6h6SIWo_"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Initializing the Loss Function and the Optimizer[link text](https://)"
      ],
      "metadata": {
        "id": "lvs4O2FIIxWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(input_dim,output_dim)"
      ],
      "metadata": {
        "id": "YyN-nb1EIttz"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.BCELoss()"
      ],
      "metadata": {
        "id": "seD9YiWsIvO3"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "liejeDKqI4u_"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Train the Model\n"
      ],
      "metadata": {
        "id": "LqtrTGrRI8rx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add a ones column - this makes the matrix multiplication work out easier\n",
        "data.insert(0, 'Ones', 1)\n",
        "\n",
        "# set X (training data) and y (target variable)\n",
        "cols = data.shape[1]\n",
        "X = data.iloc[:,0:cols-1]\n",
        "y = data.iloc[:,cols-1:cols]\n",
        "\n",
        "# convert to numpy arrays and initalize the parameter array theta\n",
        "X = np.array(X.values)\n",
        "y = np.array(y.values)\n",
        "theta = np.zeros(3)"
      ],
      "metadata": {
        "id": "rvl13nAFI-Qv"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, theta.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVsNsO_NJzxB",
        "outputId": "e807de7d-e4de-4c1b-efbd-a476fa178c9c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 3), (3,), (100, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we convert our inputs and labels from numpy arrays to tensors.\n"
      ],
      "metadata": {
        "id": "XYsqyrDBKJOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### For GPU #######\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()"
      ],
      "metadata": {
        "id": "HIXZI4j1KJ-I"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = torch.Tensor(X),torch.Tensor(y)"
      ],
      "metadata": {
        "id": "uPt-YuPOKQTo"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we build our training loop and store the losses. Every so often we can also print out the accuracy on the test data to see how our model is doing"
      ],
      "metadata": {
        "id": "ZfvYPqBlKgMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "OT-Lb-B-Kima",
        "outputId": "25530741-23dd-492a-ee7c-1f1cca8f1d55"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-f4541a116b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Computes the gradient of the given tensor w.r.t. the weights/bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Updates weights and biases with the optimizer (SGD)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0miter\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugBo3QxGt0tI"
      },
      "source": [
        "# sigmoid 函数\n",
        "g 代表一个常用的逻辑函数（logistic function）为S形函数（Sigmoid function），公式为： \\\\[g\\left( z \\right)=\\frac{1}{1+{{e}^{-z}}}\\\\] \n",
        "合起来，我们得到逻辑回归模型的假设函数： \n",
        "\t\\\\[{{h}_{\\theta }}\\left( x \\right)=\\frac{1}{1+{{e}^{-{{\\theta }^{T}}X}}}\\\\] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "783dfRz-t0tI"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK4mw4HXt0tJ"
      },
      "source": [
        "让我们做一个快速的检查，来确保它可以工作。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgUk4jC9t0tJ"
      },
      "outputs": [],
      "source": [
        "nums = np.arange(-10, 10, step=1)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "ax.plot(nums, sigmoid(nums), 'r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY5heKqct0tJ"
      },
      "source": [
        "棒极了！现在，我们需要编写代价函数来评估结果。\n",
        "代价函数：\n",
        "$J\\left( \\theta  \\right)=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[-{{y}^{(i)}}\\log \\left( {{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)-\\left( 1-{{y}^{(i)}} \\right)\\log \\left( 1-{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)]}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XmZn2wkWt0tK"
      },
      "outputs": [],
      "source": [
        "def cost(theta, X, y):\n",
        "    theta = np.matrix(theta)\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "    first = np.multiply(-y, np.log(sigmoid(X * theta.T)))\n",
        "    second = np.multiply((1 - y), np.log(1 - sigmoid(X * theta.T)))\n",
        "    return np.sum(first - second) / (len(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu0_xfact0tK"
      },
      "source": [
        "现在，我们要做一些设置，和我们在练习1在线性回归的练习很相似。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CYPsSu5Nt0tK"
      },
      "outputs": [],
      "source": [
        "# add a ones column - this makes the matrix multiplication work out easier\n",
        "data.insert(0, 'Ones', 1)\n",
        "\n",
        "# set X (training data) and y (target variable)\n",
        "cols = data.shape[1]\n",
        "X = data.iloc[:,0:cols-1]\n",
        "y = data.iloc[:,cols-1:cols]\n",
        "\n",
        "# convert to numpy arrays and initalize the parameter array theta\n",
        "X = np.array(X.values)\n",
        "y = np.array(y.values)\n",
        "theta = np.zeros(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11n9M-nut0tL"
      },
      "source": [
        "让我们来检查矩阵的维度来确保一切良好。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgVscyylt0tL"
      },
      "outputs": [],
      "source": [
        "theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DEuhp90t0tL"
      },
      "outputs": [],
      "source": [
        "X.shape, theta.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfERukwXt0tL"
      },
      "source": [
        "让我们计算初始化参数的代价函数(theta为0)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M031YkFst0tM"
      },
      "outputs": [],
      "source": [
        "cost(theta, X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsirRBy-t0tM"
      },
      "source": [
        "看起来不错，接下来，我们需要一个函数来计算我们的训练数据、标签和一些参数thata的梯度。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p-ziUDJt0tM"
      },
      "source": [
        "# gradient descent(梯度下降)\n",
        "* 这是批量梯度下降（batch gradient descent）  \n",
        "* 转化为向量化计算： $\\frac{1}{m} X^T( Sigmoid(X\\theta) - y )$\n",
        "$$\\frac{\\partial J\\left( \\theta  \\right)}{\\partial {{\\theta }_{j}}}=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{({{h}_{\\theta }}\\left( {{x}^{(i)}} \\right)-{{y}^{(i)}})x_{_{j}}^{(i)}}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "G4ABDz9vt0tM"
      },
      "outputs": [],
      "source": [
        "def gradient(theta, X, y):\n",
        "    theta = np.matrix(theta)\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "    \n",
        "    parameters = int(theta.ravel().shape[1])\n",
        "    grad = np.zeros(parameters)\n",
        "    \n",
        "    error = sigmoid(X * theta.T) - y\n",
        "    \n",
        "    for i in range(parameters):\n",
        "        term = np.multiply(error, X[:,i])\n",
        "        grad[i] = np.sum(term) / len(X)\n",
        "    \n",
        "    return grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI8jXxWPt0tM"
      },
      "source": [
        "注意，我们实际上没有在这个函数中执行梯度下降，我们仅仅在计算一个梯度步长。在练习中，一个称为“fminunc”的Octave函数是用来优化函数来计算成本和梯度参数。由于我们使用Python，我们可以用SciPy的“optimize”命名空间来做同样的事情。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BXGxNVwt0tN"
      },
      "source": [
        "我们看看用我们的数据和初始参数为0的梯度下降法的结果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77erS_iwt0tN"
      },
      "outputs": [],
      "source": [
        "gradient(theta, X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thK3cMbCt0tN"
      },
      "source": [
        "现在可以用SciPy's truncated newton（TNC）实现寻找最优参数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0u89TZpt0tN"
      },
      "outputs": [],
      "source": [
        "import scipy.optimize as opt\n",
        "result = opt.fmin_tnc(func=cost, x0=theta, fprime=gradient, args=(X, y))\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDQiiOYst0tN"
      },
      "source": [
        "让我们看看在这个结论下代价函数计算结果是什么个样子~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfSnAlaYt0tO"
      },
      "outputs": [],
      "source": [
        "cost(result[0], X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WVZ409ot0tO"
      },
      "source": [
        "接下来，我们需要编写一个函数，用我们所学的参数theta来为数据集X输出预测。然后，我们可以使用这个函数来给我们的分类器的训练精度打分。\n",
        "逻辑回归模型的假设函数： \n",
        "\t\\\\[{{h}_{\\theta }}\\left( x \\right)=\\frac{1}{1+{{e}^{-{{\\theta }^{T}}X}}}\\\\] \n",
        "当${{h}_{\\theta }}$大于等于0.5时，预测 y=1\n",
        "\n",
        "当${{h}_{\\theta }}$小于0.5时，预测 y=0 。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "blgtRwvXt0tO"
      },
      "outputs": [],
      "source": [
        "def predict(theta, X):\n",
        "    probability = sigmoid(X * theta.T)\n",
        "    return [1 if x >= 0.5 else 0 for x in probability]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARQO9y2At0tO"
      },
      "outputs": [],
      "source": [
        "theta_min = np.matrix(result[0])\n",
        "predictions = predict(theta_min, X)\n",
        "correct = [1 if ((a == 1 and b == 1) or (a == 0 and b == 0)) else 0 for (a, b) in zip(predictions, y)]\n",
        "accuracy = (sum(map(int, correct)) % len(correct))\n",
        "print ('accuracy = {0}%'.format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjPiNb49t0tP"
      },
      "source": [
        "我们的逻辑回归分类器预测正确，如果一个学生被录取或没有录取，达到89%的精确度。不坏！记住，这是训练集的准确性。我们没有保持住了设置或使用交叉验证得到的真实逼近，所以这个数字有可能高于其真实值（这个话题将在以后说明）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyd5CXmPt0tP"
      },
      "source": [
        "## 正则化逻辑回归"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE1SqmFat0tP"
      },
      "source": [
        "在训练的第二部分，我们将要通过加入正则项提升逻辑回归算法。如果你对正则化有点眼生，或者喜欢这一节的方程的背景，请参考在\"exercises\"文件夹中的\"ex2.pdf\"。简而言之，正则化是成本函数中的一个术语，它使算法更倾向于“更简单”的模型（在这种情况下，模型将更小的系数）。这个理论助于减少过拟合，提高模型的泛化能力。这样，我们开始吧。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QoIOSzZt0tP"
      },
      "source": [
        "设想你是工厂的生产主管，你有一些芯片在两次测试中的测试结果。对于这两次测试，你想决定是否芯片要被接受或抛弃。为了帮助你做出艰难的决定，你拥有过去芯片的测试数据集，从其中你可以构建一个逻辑回归模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txnZFx84t0tP"
      },
      "source": [
        "和第一部分很像，从数据可视化开始吧！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yeWagXqt0tP"
      },
      "outputs": [],
      "source": [
        "path =  'ex2data2.txt'\n",
        "data2 = pd.read_csv(path, header=None, names=['Test 1', 'Test 2', 'Accepted'])\n",
        "data2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yA1z19bt0tQ"
      },
      "outputs": [],
      "source": [
        "positive = data2[data2['Accepted'].isin([1])]\n",
        "negative = data2[data2['Accepted'].isin([0])]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "ax.scatter(positive['Test 1'], positive['Test 2'], s=50, c='b', marker='o', label='Accepted')\n",
        "ax.scatter(negative['Test 1'], negative['Test 2'], s=50, c='r', marker='x', label='Rejected')\n",
        "ax.legend()\n",
        "ax.set_xlabel('Test 1 Score')\n",
        "ax.set_ylabel('Test 2 Score')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9lLgD8et0tQ"
      },
      "source": [
        "哇，这个数据看起来可比前一次的复杂得多。特别地，你会注意到其中没有线性决策界限，来良好的分开两类数据。一个方法是用像逻辑回归这样的线性技术来构造从原始特征的多项式中得到的特征。让我们通过创建一组多项式特征入手吧。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2A9daewnt0tQ"
      },
      "outputs": [],
      "source": [
        "degree = 5\n",
        "x1 = data2['Test 1']\n",
        "x2 = data2['Test 2']\n",
        "\n",
        "data2.insert(3, 'Ones', 1)\n",
        "\n",
        "for i in range(1, degree):\n",
        "    for j in range(0, i):\n",
        "        data2['F' + str(i) + str(j)] = np.power(x1, i-j) * np.power(x2, j)\n",
        "\n",
        "data2.drop('Test 1', axis=1, inplace=True)\n",
        "data2.drop('Test 2', axis=1, inplace=True)\n",
        "\n",
        "data2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M6O_YLQt0tQ"
      },
      "source": [
        "现在，我们需要修改第1部分的成本和梯度函数，包括正则化项。首先是成本函数："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKs0okedt0tQ"
      },
      "source": [
        "# regularized cost（正则化代价函数）\n",
        "$$J\\left( \\theta  \\right)=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[-{{y}^{(i)}}\\log \\left( {{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)-\\left( 1-{{y}^{(i)}} \\right)\\log \\left( 1-{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)]}+\\frac{\\lambda }{2m}\\sum\\limits_{j=1}^{n}{\\theta _{j}^{2}}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XrIsm1APt0tR"
      },
      "outputs": [],
      "source": [
        "def cost(theta, X, y, learningRate):\n",
        "    theta = np.matrix(theta)\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "    first = np.multiply(-y, np.log(sigmoid(X * theta.T)))\n",
        "    second = np.multiply((1 - y), np.log(1 - sigmoid(X * theta.T)))\n",
        "    reg = (learningRate / (2 * len(X))) * np.sum(np.power(theta[:,1:theta.shape[1]], 2))\n",
        "    return np.sum(first - second) / len(X) + reg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6ivXppjt0tR"
      },
      "source": [
        "请注意等式中的\"reg\" 项。还注意到另外的一个“学习率”参数。这是一种超参数，用来控制正则化项。现在我们需要添加正则化梯度函数："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1gPPOqPt0tR"
      },
      "source": [
        "如果我们要使用梯度下降法令这个代价函数最小化，因为我们未对${{\\theta }_{0}}$ 进行正则化，所以梯度下降算法将分两种情形：\n",
        "\\begin{align}\n",
        "  & Repeat\\text{ }until\\text{ }convergence\\text{ }\\!\\!\\{\\!\\!\\text{ } \\\\ \n",
        " & \\text{     }{{\\theta }_{0}}:={{\\theta }_{0}}-a\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right)-{{y}^{(i)}}]x_{_{0}}^{(i)}} \\\\ \n",
        " & \\text{     }{{\\theta }_{j}}:={{\\theta }_{j}}-a\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right)-{{y}^{(i)}}]x_{j}^{(i)}}+\\frac{\\lambda }{m}{{\\theta }_{j}} \\\\ \n",
        " & \\text{          }\\!\\!\\}\\!\\!\\text{ } \\\\ \n",
        " & Repeat \\\\ \n",
        "\\end{align}\n",
        "\n",
        "对上面的算法中 j=1,2,...,n 时的更新式子进行调整可得： \n",
        "${{\\theta }_{j}}:={{\\theta }_{j}}(1-a\\frac{\\lambda }{m})-a\\frac{1}{m}\\sum\\limits_{i=1}^{m}{({{h}_{\\theta }}\\left( {{x}^{(i)}} \\right)-{{y}^{(i)}})x_{j}^{(i)}}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NeQBw0Egt0tR"
      },
      "outputs": [],
      "source": [
        "def gradientReg(theta, X, y, learningRate):\n",
        "    theta = np.matrix(theta)\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "    \n",
        "    parameters = int(theta.ravel().shape[1])\n",
        "    grad = np.zeros(parameters)\n",
        "    \n",
        "    error = sigmoid(X * theta.T) - y\n",
        "    \n",
        "    for i in range(parameters):\n",
        "        term = np.multiply(error, X[:,i])\n",
        "        \n",
        "        if (i == 0):\n",
        "            grad[i] = np.sum(term) / len(X)\n",
        "        else:\n",
        "            grad[i] = (np.sum(term) / len(X)) + ((learningRate / len(X)) * theta[:,i])\n",
        "    \n",
        "    return grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyO21e2Xt0tR"
      },
      "source": [
        "就像在第一部分中做的一样，初始化变量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WQibSd_Lt0tR"
      },
      "outputs": [],
      "source": [
        "# set X and y (remember from above that we moved the label to column 0)\n",
        "cols = data2.shape[1]\n",
        "X2 = data2.iloc[:,1:cols]\n",
        "y2 = data2.iloc[:,0:1]\n",
        "\n",
        "# convert to numpy arrays and initalize the parameter array theta\n",
        "X2 = np.array(X2.values)\n",
        "y2 = np.array(y2.values)\n",
        "theta2 = np.zeros(11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojjc-7c2t0tS"
      },
      "source": [
        "让我们初始学习率到一个合理值。，果有必要的话（即如果惩罚太强或不够强）,我们可以之后再折腾这个。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NwwrNwZ7t0tS"
      },
      "outputs": [],
      "source": [
        "learningRate = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b21fKOrVt0tS"
      },
      "source": [
        "现在，让我们尝试调用新的默认为0的theta的正则化函数，以确保计算工作正常。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrSHrvy_t0tS"
      },
      "outputs": [],
      "source": [
        "costReg(theta2, X2, y2, learningRate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY3-5K1wt0tS"
      },
      "outputs": [],
      "source": [
        "gradientReg(theta2, X2, y2, learningRate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBDiMM9Wt0tS"
      },
      "source": [
        "现在我们可以使用和第一部分相同的优化函数来计算优化后的结果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSpa1Hubt0tT"
      },
      "outputs": [],
      "source": [
        "result2 = opt.fmin_tnc(func=costReg, x0=theta2, fprime=gradientReg, args=(X2, y2, learningRate))\n",
        "result2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C6Mu8Tdt0tT"
      },
      "source": [
        "最后，我们可以使用第1部分中的预测函数来查看我们的方案在训练数据上的准确度。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHc0Lc4ct0tT"
      },
      "outputs": [],
      "source": [
        "theta_min = np.matrix(result2[0])\n",
        "predictions = predict(theta_min, X2)\n",
        "correct = [1 if ((a == 1 and b == 1) or (a == 0 and b == 0)) else 0 for (a, b) in zip(predictions, y2)]\n",
        "accuracy = (sum(map(int, correct)) % len(correct))\n",
        "print ('accuracy = {0}%'.format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADdy89yft0tT"
      },
      "source": [
        "虽然我们实现了这些算法，值得注意的是，我们还可以使用高级Python库像scikit-learn来解决这个问题。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8kWyNait0tT"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model#调用sklearn的线性回归包\n",
        "model = linear_model.LogisticRegression(penalty='l2', C=1.0)\n",
        "model.fit(X2, y2.ravel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_itWjzyFt0tT"
      },
      "outputs": [],
      "source": [
        "model.score(X2, y2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWZGmUR5t0tT"
      },
      "source": [
        "这个准确度和我们刚刚实现的差了好多，不过请记住这个结果可以使用默认参数下计算的结果。我们可能需要做一些参数的调整来获得和我们之前结果相同的精确度。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOi9L60ct0tU"
      },
      "source": [
        "这就是练习2的全部！ 敬请期待下一个练习：多类图像分类。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-Nm2A2hjt0tU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "ML-Exercise2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}